#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenAI å…¬ç›Šç«™æ£€æµ‹å·¥å…·
ç”¨äºæµ‹è¯• OpenAI å…¼å®¹æ¥å£çš„å„ç§åŠŸèƒ½
"""

import json
import time
import sys
from typing import Optional, Dict, Any, List

try:
    import requests
except ImportError:
    print("è¯·å…ˆå®‰è£… requests: pip install requests")
    sys.exit(1)

try:
    from rich.console import Console
    from rich.table import Table
    from rich.panel import Panel
    from rich.progress import Progress, SpinnerColumn, TextColumn
    from rich import print as rprint
except ImportError:
    print("è¯·å…ˆå®‰è£… rich: pip install rich")
    sys.exit(1)

console = Console()


class OpenAITester:
    """OpenAI æ¥å£æµ‹è¯•å™¨"""
    
    def __init__(self, base_url: str, api_key: str):
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        self.results = {}
        self.all_test_history = []  # ä¿å­˜æ‰€æœ‰æµ‹è¯•å†å²ï¼Œç”¨äºæœ€ç»ˆæŠ¥å‘Š
        
    def _make_request(self, method: str, endpoint: str, data: Optional[Dict] = None, 
                      stream: bool = False, timeout: int = 30) -> requests.Response:
        """å‘é€ HTTP è¯·æ±‚"""
        url = f"{self.base_url}{endpoint}"
        if method.upper() == "GET":
            return requests.get(url, headers=self.headers, timeout=timeout)
        elif method.upper() == "POST":
            return requests.post(url, headers=self.headers, json=data, 
                               stream=stream, timeout=timeout)
        raise ValueError(f"ä¸æ”¯æŒçš„ HTTP æ–¹æ³•: {method}")
    
    def test_models_list(self) -> Dict[str, Any]:
        """æµ‹è¯•è·å–æ¨¡å‹åˆ—è¡¨"""
        console.print("\n[bold cyan]ğŸ“‹ æµ‹è¯•æ¨¡å‹åˆ—è¡¨...[/bold cyan]")
        result = {
            "success": False,
            "models": [],
            "error": None,
            "response_time": 0
        }
        
        try:
            start_time = time.time()
            response = self._make_request("GET", "/models")
            result["response_time"] = round(time.time() - start_time, 3)
            
            if response.status_code == 200:
                data = response.json()
                models = data.get("data", [])
                result["success"] = True
                result["models"] = [m.get("id", "unknown") for m in models]
                
                # æ˜¾ç¤ºæ¨¡å‹åˆ—è¡¨
                if result["models"]:
                    table = Table(title="æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨", show_header=True, header_style="bold magenta")
                    table.add_column("åºå·", style="cyan", width=6)
                    table.add_column("æ¨¡å‹åç§°", style="green")
                    
                    for i, model in enumerate(result["models"], 1):
                        table.add_row(str(i), model)
                    
                    console.print(table)
                    console.print(f"[green]âœ… æˆåŠŸè·å– {len(result['models'])} ä¸ªæ¨¡å‹[/green]")
                else:
                    console.print("[yellow]âš ï¸ æ¨¡å‹åˆ—è¡¨ä¸ºç©º[/yellow]")
            else:
                result["error"] = f"HTTP {response.status_code}: {response.text[:200]}"
                console.print(f"[red]âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {result['error']}[/red]")
                
        except requests.exceptions.Timeout:
            result["error"] = "è¯·æ±‚è¶…æ—¶"
            console.print("[red]âŒ è¯·æ±‚è¶…æ—¶[/red]")
        except requests.exceptions.ConnectionError as e:
            result["error"] = f"è¿æ¥é”™è¯¯: {str(e)}"
            console.print(f"[red]âŒ è¿æ¥é”™è¯¯: {e}[/red]")
        except Exception as e:
            result["error"] = str(e)
            console.print(f"[red]âŒ é”™è¯¯: {e}[/red]")
            
        self.results["models_list"] = result
        return result
    
    def test_chat_completion(self, model: Optional[str] = None) -> Dict[str, Any]:
        """æµ‹è¯•åŸºç¡€å¯¹è¯åŠŸèƒ½"""
        console.print("\n[bold cyan]ğŸ’¬ æµ‹è¯•åŸºç¡€å¯¹è¯...[/bold cyan]")
        result = {
            "success": False,
            "model_used": model,
            "response": None,
            "error": None,
            "response_time": 0
        }
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹ï¼Œå°è¯•ä½¿ç”¨å·²è·å–çš„æ¨¡å‹åˆ—è¡¨ä¸­çš„ç¬¬ä¸€ä¸ª
        if not model:
            models_result = self.results.get("models_list", {})
            if models_result.get("models"):
                # ä¼˜å…ˆé€‰æ‹© gpt ç›¸å…³æ¨¡å‹
                for m in models_result["models"]:
                    if "gpt" in m.lower():
                        model = m
                        break
                if not model:
                    model = models_result["models"][0]
            else:
                model = "gpt-3.5-turbo"  # é»˜è®¤æ¨¡å‹
        
        result["model_used"] = model
        console.print(f"[dim]ä½¿ç”¨æ¨¡å‹: {model}[/dim]")
        
        payload = {
            "model": model,
            "messages": [
                {"role": "user", "content": "è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"}
            ],
            "max_tokens": 100
        }
        
        try:
            start_time = time.time()
            response = self._make_request("POST", "/chat/completions", payload)
            result["response_time"] = round(time.time() - start_time, 3)
            
            if response.status_code == 200:
                data = response.json()
                content = data.get("choices", [{}])[0].get("message", {}).get("content", "")
                result["success"] = True
                result["response"] = content
                console.print(f"[green]âœ… å¯¹è¯æˆåŠŸ[/green]")
                console.print(Panel(content, title="AI å›å¤", border_style="green"))
            else:
                result["error"] = f"HTTP {response.status_code}: {response.text[:200]}"
                console.print(f"[red]âŒ å¯¹è¯å¤±è´¥: {result['error']}[/red]")
                
        except requests.exceptions.Timeout:
            result["error"] = "è¯·æ±‚è¶…æ—¶"
            console.print("[red]âŒ è¯·æ±‚è¶…æ—¶[/red]")
        except Exception as e:
            result["error"] = str(e)
            console.print(f"[red]âŒ é”™è¯¯: {e}[/red]")
            
        self.results["chat_completion"] = result
        return result
    
    def test_stream_mode(self, model: Optional[str] = None) -> Dict[str, Any]:
        """æµ‹è¯•æµå¼è¾“å‡º - å¢å¼ºç‰ˆï¼Œå¯¹æ¯”æµå¼å’Œéæµå¼å“åº”"""
        console.print("\n[bold cyan]ğŸŒŠ æµ‹è¯• Stream æµå¼è¾“å‡º...[/bold cyan]")
        result = {
            "success": False,
            "model_used": model,
            "chunks_received": 0,
            "full_response": "",
            "error": None,
            "response_time": 0,
            "is_real_stream": False,  # æ˜¯å¦çœŸæ­£çš„æµå¼
            "first_chunk_time": 0,    # é¦–ä¸ªæ•°æ®å—æ—¶é—´
            "stream_quality": "unknown"  # æµå¼è´¨é‡è¯„ä¼°
        }
        
        # é€‰æ‹©æ¨¡å‹
        if not model:
            models_result = self.results.get("models_list", {})
            if models_result.get("models"):
                for m in models_result["models"]:
                    if "gpt" in m.lower():
                        model = m
                        break
                if not model:
                    model = models_result["models"][0]
            else:
                model = "gpt-3.5-turbo"
        
        result["model_used"] = model
        console.print(f"[dim]ä½¿ç”¨æ¨¡å‹: {model}[/dim]")
        
        # æµ‹è¯•ç”¨çš„æ¶ˆæ¯
        test_message = "è¯·ä»1æ•°åˆ°10ï¼Œæ¯ä¸ªæ•°å­—å•ç‹¬è¾“å‡º"
        
        payload_stream = {
            "model": model,
            "messages": [
                {"role": "user", "content": test_message}
            ],
            "max_tokens": 100,
            "stream": True
        }
        
        try:
            start_time = time.time()
            first_chunk_time = None
            chunk_times = []  # è®°å½•æ¯ä¸ªæ•°æ®å—çš„æ—¶é—´
            response = self._make_request("POST", "/chat/completions", payload_stream, stream=True, timeout=60)
            
            if response.status_code == 200:
                full_content = ""
                chunk_count = 0
                raw_lines = []
                has_done = False
                
                console.print("[dim]æ¥æ”¶æµå¼æ•°æ®: [/dim]", end="")
                
                for line in response.iter_lines():
                    current_time = time.time()
                    
                    if line:
                        try:
                            line_str = line.decode('utf-8')
                        except:
                            line_str = str(line)
                        
                        raw_lines.append(line_str)
                        
                        # å¤„ç†æ ‡å‡† SSE æ ¼å¼: data: {...}
                        if line_str.startswith("data: "):
                            data_str = line_str[6:]
                            if data_str.strip() == "[DONE]":
                                has_done = True
                                break
                            try:
                                data = json.loads(data_str)
                                delta = data.get("choices", [{}])[0].get("delta", {})
                                content = delta.get("content", "")
                                if content:
                                    if first_chunk_time is None:
                                        first_chunk_time = current_time - start_time
                                    chunk_times.append(current_time - start_time)
                                    full_content += content
                                    chunk_count += 1
                                    console.print(f"[cyan]{content}[/cyan]", end="")
                            except json.JSONDecodeError:
                                pass
                        # å¤„ç†æŸäº› API ç›´æ¥è¿”å› JSON çš„æƒ…å†µ
                        elif line_str.startswith("{"):
                            try:
                                data = json.loads(line_str)
                                delta = data.get("choices", [{}])[0].get("delta", {})
                                content = delta.get("content", "")
                                if not content:
                                    content = data.get("content", "")
                                if not content:
                                    content = data.get("completion", "")
                                if content:
                                    if first_chunk_time is None:
                                        first_chunk_time = current_time - start_time
                                    chunk_times.append(current_time - start_time)
                                    full_content += content
                                    chunk_count += 1
                                    console.print(f"[cyan]{content}[/cyan]", end="")
                            except json.JSONDecodeError:
                                pass
                        elif line_str.startswith("event:"):
                            pass
                
                console.print()  # æ¢è¡Œ
                total_time = time.time() - start_time
                result["response_time"] = round(total_time, 3)
                result["first_chunk_time"] = round(first_chunk_time, 3) if first_chunk_time else 0
                
                # åˆ†ææµå¼è´¨é‡
                if chunk_count > 0:
                    result["chunks_received"] = chunk_count
                    result["full_response"] = full_content
                    
                    # è®¡ç®—æ•°æ®å—ä¹‹é—´çš„æ—¶é—´é—´éš”
                    if len(chunk_times) > 1:
                        intervals = [chunk_times[i+1] - chunk_times[i] for i in range(len(chunk_times)-1)]
                        avg_interval = sum(intervals) / len(intervals)
                        
                        # åˆ¤æ–­æ˜¯å¦æ˜¯çœŸæ­£çš„æµå¼
                        # çœŸæ­£çš„æµå¼ï¼šæ•°æ®å—ä¹‹é—´æœ‰æ˜æ˜¾çš„æ—¶é—´é—´éš”
                        if avg_interval > 0.01 and chunk_count >= 3:  # å¹³å‡é—´éš” > 10ms ä¸”è‡³å°‘3ä¸ªå—
                            result["is_real_stream"] = True
                            result["stream_quality"] = "excellent"
                            result["success"] = True
                            console.print(f"[green]âœ… çœŸæ­£çš„æµå¼è¾“å‡º! æ”¶åˆ° {chunk_count} ä¸ªæ•°æ®å—[/green]")
                            console.print(f"[dim]   é¦–å­—èŠ‚æ—¶é—´: {result['first_chunk_time']}s, å¹³å‡é—´éš”: {round(avg_interval*1000, 1)}ms[/dim]")
                        elif chunk_count >= 2:
                            result["is_real_stream"] = True
                            result["stream_quality"] = "good"
                            result["success"] = True
                            console.print(f"[green]âœ… æµå¼è¾“å‡ºæ”¯æŒ! æ”¶åˆ° {chunk_count} ä¸ªæ•°æ®å—[/green]")
                        else:
                            result["stream_quality"] = "poor"
                            result["success"] = True
                            console.print(f"[yellow]âš ï¸ æµå¼è¾“å‡ºå¯èƒ½æ˜¯ä¼ªæµå¼ (æ•°æ®å—å¤ªå°‘)[/yellow]")
                    else:
                        # åªæœ‰ä¸€ä¸ªæ•°æ®å—
                        result["stream_quality"] = "poor"
                        result["success"] = True
                        console.print(f"[yellow]âš ï¸ åªæ”¶åˆ° 1 ä¸ªæ•°æ®å—ï¼Œå¯èƒ½æ˜¯ä¼ªæµå¼[/yellow]")
                        
                elif full_content:
                    result["success"] = True
                    result["chunks_received"] = 1
                    result["full_response"] = full_content
                    result["stream_quality"] = "non-standard"
                    console.print(f"[yellow]âš ï¸ éæ ‡å‡†æµå¼æ ¼å¼[/yellow]")
                else:
                    # æ²¡æœ‰æ”¶åˆ°å†…å®¹
                    result["success"] = False
                    
                    # æ£€æŸ¥æ˜¯å¦åªæœ‰ [DONE]
                    if has_done and len(raw_lines) <= 2:
                        result["error"] = "API è¿”å›ç©ºæµå¼å“åº” (åªæœ‰ [DONE])"
                        result["stream_quality"] = "not_supported"
                        console.print(f"[red]âŒ æµå¼ä¸æ”¯æŒ: API ç›´æ¥è¿”å› [DONE]ï¼Œæ²¡æœ‰å®é™…æ•°æ®[/red]")
                        console.print(f"[yellow]   è¿™é€šå¸¸æ„å‘³ç€è¯¥æ¨¡å‹/API ä¸æ”¯æŒçœŸæ­£çš„æµå¼è¾“å‡º[/yellow]")
                    else:
                        result["error"] = "æœªæ”¶åˆ°æœ‰æ•ˆçš„æµå¼æ•°æ®"
                        result["stream_quality"] = "unknown"
                        console.print(f"[yellow]âš ï¸ æ”¶åˆ° 0 ä¸ªæ•°æ®å—[/yellow]")
                        if raw_lines:
                            console.print(f"[dim]åŸå§‹å“åº” (å‰5è¡Œ):[/dim]")
                            for i, raw_line in enumerate(raw_lines[:5]):
                                console.print(f"[dim]  {i+1}: {raw_line[:150]}{'...' if len(raw_line) > 150 else ''}[/dim]")
                    
                    # å°è¯•éæµå¼è¯·æ±‚ä½œä¸ºå¯¹æ¯”
                    console.print(f"\n[dim]æ­£åœ¨è¿›è¡Œéæµå¼å¯¹æ¯”æµ‹è¯•...[/dim]")
                    try:
                        payload_non_stream = {
                            "model": model,
                            "messages": [{"role": "user", "content": "è¯´'æµ‹è¯•æˆåŠŸ'"}],
                            "max_tokens": 20,
                            "stream": False
                        }
                        non_stream_start = time.time()
                        non_stream_resp = self._make_request("POST", "/chat/completions", payload_non_stream, timeout=30)
                        non_stream_time = time.time() - non_stream_start
                        
                        if non_stream_resp.status_code == 200:
                            data = non_stream_resp.json()
                            content = data.get("choices", [{}])[0].get("message", {}).get("content", "")
                            if content:
                                console.print(f"[green]   éæµå¼è¯·æ±‚æˆåŠŸ ({round(non_stream_time, 2)}s): {content[:50]}[/green]")
                                console.print(f"[yellow]   ç»“è®º: API å¯ç”¨ï¼Œä½†æµå¼æ¨¡å¼å¯èƒ½ä¸è¢«è¯¥æ¨¡å‹æ”¯æŒ[/yellow]")
                            else:
                                console.print(f"[yellow]   éæµå¼è¯·æ±‚è¿”å›ç©ºå†…å®¹[/yellow]")
                        else:
                            console.print(f"[red]   éæµå¼è¯·æ±‚ä¹Ÿå¤±è´¥: HTTP {non_stream_resp.status_code}[/red]")
                    except Exception as e:
                        console.print(f"[red]   éæµå¼å¯¹æ¯”æµ‹è¯•å¤±è´¥: {e}[/red]")
                        
            else:
                result["error"] = f"HTTP {response.status_code}: {response.text[:200]}"
                console.print(f"[red]âŒ Stream æµ‹è¯•å¤±è´¥: {result['error']}[/red]")
                
        except requests.exceptions.Timeout:
            result["error"] = "è¯·æ±‚è¶…æ—¶"
            console.print("[red]âŒ è¯·æ±‚è¶…æ—¶[/red]")
        except Exception as e:
            result["error"] = str(e)
            console.print(f"[red]âŒ é”™è¯¯: {e}[/red]")
            
        self.results["stream_mode"] = result
        return result
    
    def test_function_calling(self, model: Optional[str] = None) -> Dict[str, Any]:
        """æµ‹è¯•å·¥å…·/å‡½æ•°è°ƒç”¨"""
        console.print("\n[bold cyan]ğŸ”§ æµ‹è¯•å·¥å…·è°ƒç”¨ (Function Calling)...[/bold cyan]")
        result = {
            "success": False,
            "model_used": model,
            "tool_called": False,
            "tool_name": None,
            "tool_arguments": None,
            "error": None,
            "response_time": 0
        }
        
        # é€‰æ‹©æ¨¡å‹
        if not model:
            models_result = self.results.get("models_list", {})
            if models_result.get("models"):
                for m in models_result["models"]:
                    if "gpt" in m.lower():
                        model = m
                        break
                if not model:
                    model = models_result["models"][0]
            else:
                model = "gpt-3.5-turbo"
        
        result["model_used"] = model
        console.print(f"[dim]ä½¿ç”¨æ¨¡å‹: {model}[/dim]")
        
        # å®šä¹‰ä¸€ä¸ªç®€å•çš„å·¥å…·
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "get_weather",
                    "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "city": {
                                "type": "string",
                                "description": "åŸå¸‚åç§°ï¼Œå¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·"
                            }
                        },
                        "required": ["city"]
                    }
                }
            }
        ]
        
        payload = {
            "model": model,
            "messages": [
                {"role": "user", "content": "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}
            ],
            "tools": tools,
            "tool_choice": "auto",
            "max_tokens": 200
        }
        
        try:
            start_time = time.time()
            response = self._make_request("POST", "/chat/completions", payload)
            result["response_time"] = round(time.time() - start_time, 3)
            
            if response.status_code == 200:
                data = response.json()
                message = data.get("choices", [{}])[0].get("message", {})
                tool_calls = message.get("tool_calls", [])
                
                if tool_calls:
                    result["success"] = True
                    result["tool_called"] = True
                    result["tool_name"] = tool_calls[0].get("function", {}).get("name")
                    result["tool_arguments"] = tool_calls[0].get("function", {}).get("arguments")
                    
                    console.print(f"[green]âœ… å·¥å…·è°ƒç”¨æ”¯æŒ![/green]")
                    console.print(f"[dim]è°ƒç”¨çš„å·¥å…·: {result['tool_name']}[/dim]")
                    console.print(f"[dim]å‚æ•°: {result['tool_arguments']}[/dim]")
                else:
                    # æ£€æŸ¥æ˜¯å¦è¿”å›äº†æ™®é€šå›å¤ï¼ˆå¯èƒ½ä¸æ”¯æŒå·¥å…·è°ƒç”¨ï¼‰
                    content = message.get("content", "")
                    if content:
                        result["success"] = True
                        result["tool_called"] = False
                        console.print(f"[yellow]âš ï¸ æ¨¡å‹è¿”å›äº†æ™®é€šå›å¤ï¼Œå¯èƒ½ä¸æ”¯æŒå·¥å…·è°ƒç”¨[/yellow]")
                        console.print(f"[dim]å›å¤: {content[:100]}...[/dim]")
                    else:
                        result["error"] = "æœªæ”¶åˆ°æœ‰æ•ˆå“åº”"
                        console.print("[red]âŒ æœªæ”¶åˆ°æœ‰æ•ˆå“åº”[/red]")
            else:
                result["error"] = f"HTTP {response.status_code}: {response.text[:200]}"
                console.print(f"[red]âŒ å·¥å…·è°ƒç”¨æµ‹è¯•å¤±è´¥: {result['error']}[/red]")
                
        except requests.exceptions.Timeout:
            result["error"] = "è¯·æ±‚è¶…æ—¶"
            console.print("[red]âŒ è¯·æ±‚è¶…æ—¶[/red]")
        except Exception as e:
            result["error"] = str(e)
            console.print(f"[red]âŒ é”™è¯¯: {e}[/red]")
            
        self.results["function_calling"] = result
        return result
    
    def test_embeddings(self, model: Optional[str] = None) -> Dict[str, Any]:
        """æµ‹è¯•æ–‡æœ¬åµŒå…¥åŠŸèƒ½"""
        console.print("\n[bold cyan]ğŸ“Š æµ‹è¯• Embeddings æ–‡æœ¬åµŒå…¥...[/bold cyan]")
        result = {
            "success": False,
            "model_used": model,
            "dimensions": 0,
            "error": None,
            "response_time": 0
        }
        
        # é€‰æ‹©åµŒå…¥æ¨¡å‹
        if not model:
            models_result = self.results.get("models_list", {})
            if models_result.get("models"):
                for m in models_result["models"]:
                    if "embed" in m.lower():
                        model = m
                        break
                if not model:
                    model = "text-embedding-ada-002"
            else:
                model = "text-embedding-ada-002"
        
        result["model_used"] = model
        console.print(f"[dim]ä½¿ç”¨æ¨¡å‹: {model}[/dim]")
        
        payload = {
            "model": model,
            "input": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
        }
        
        try:
            start_time = time.time()
            response = self._make_request("POST", "/embeddings", payload)
            result["response_time"] = round(time.time() - start_time, 3)
            
            if response.status_code == 200:
                data = response.json()
                embeddings = data.get("data", [{}])[0].get("embedding", [])
                result["success"] = True
                result["dimensions"] = len(embeddings)
                console.print(f"[green]âœ… Embeddings æ”¯æŒ! å‘é‡ç»´åº¦: {result['dimensions']}[/green]")
            else:
                result["error"] = f"HTTP {response.status_code}: {response.text[:200]}"
                console.print(f"[red]âŒ Embeddings æµ‹è¯•å¤±è´¥: {result['error']}[/red]")
                
        except requests.exceptions.Timeout:
            result["error"] = "è¯·æ±‚è¶…æ—¶"
            console.print("[red]âŒ è¯·æ±‚è¶…æ—¶[/red]")
        except Exception as e:
            result["error"] = str(e)
            console.print(f"[red]âŒ é”™è¯¯: {e}[/red]")
            
        self.results["embeddings"] = result
        return result
    
    def select_model(self, show_exit_option: bool = False) -> Optional[str]:
        """è®©ç”¨æˆ·é€‰æ‹©æ¨¡å‹
        
        Args:
            show_exit_option: æ˜¯å¦æ˜¾ç¤ºé€€å‡ºé€‰é¡¹ (è¾“å…¥ 0 é€€å‡º)
        
        Returns:
            é€‰æ‹©çš„æ¨¡å‹åï¼Œå¦‚æœç”¨æˆ·é€‰æ‹©é€€å‡ºåˆ™è¿”å› "__EXIT__"
        """
        models_result = self.results.get("models_list", {})
        models = models_result.get("models", [])
        
        if not models:
            console.print("[yellow]âš ï¸ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œå°†ä½¿ç”¨é»˜è®¤æ¨¡å‹[/yellow]")
            return None
        
        console.print("\n[bold]è¯·é€‰æ‹©è¦æµ‹è¯•çš„æ¨¡å‹:[/bold]")
        if show_exit_option:
            console.print("[dim]è¾“å…¥åºå·é€‰æ‹©æ¨¡å‹ï¼Œè¾“å…¥ 0 é€€å‡ºç¨‹åº[/dim]\n")
        else:
            console.print("[dim]è¾“å…¥åºå·é€‰æ‹©æ¨¡å‹ï¼Œæˆ–ç›´æ¥è¾“å…¥æ¨¡å‹åç§°[/dim]\n")
        
        # åˆ†ç±»æ˜¾ç¤ºæ¨¡å‹
        chat_models = []
        embed_models = []
        other_models = []
        
        for m in models:
            m_lower = m.lower()
            if "embed" in m_lower:
                embed_models.append(m)
            elif any(x in m_lower for x in ["gpt", "claude", "llama", "qwen", "glm", "chat"]):
                chat_models.append(m)
            else:
                other_models.append(m)
        
        # åˆ›å»ºå¸¦åˆ†ç±»çš„æ¨¡å‹åˆ—è¡¨
        all_models_ordered = []
        
        if chat_models:
            console.print("[bold cyan]ğŸ’¬ å¯¹è¯æ¨¡å‹:[/bold cyan]")
            for i, m in enumerate(chat_models, 1):
                console.print(f"  [cyan]{i}[/cyan]. {m}")
                all_models_ordered.append(m)
        
        offset = len(chat_models)
        if embed_models:
            console.print("[bold green]ğŸ“Š åµŒå…¥æ¨¡å‹:[/bold green]")
            for i, m in enumerate(embed_models, offset + 1):
                console.print(f"  [green]{i}[/green]. {m}")
                all_models_ordered.append(m)
        
        offset += len(embed_models)
        if other_models:
            console.print("[bold yellow]ğŸ“¦ å…¶ä»–æ¨¡å‹:[/bold yellow]")
            for i, m in enumerate(other_models, offset + 1):
                console.print(f"  [yellow]{i}[/yellow]. {m}")
                all_models_ordered.append(m)
        
        console.print()
        
        while True:
            choice = console.input("[bold]è¯·è¾“å…¥é€‰æ‹© (åºå·æˆ–æ¨¡å‹å): [/bold]").strip()
            
            if not choice:
                # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªå¯¹è¯æ¨¡å‹
                if chat_models:
                    selected = chat_models[0]
                    console.print(f"[dim]ä½¿ç”¨é»˜è®¤æ¨¡å‹: {selected}[/dim]")
                    return selected
                elif all_models_ordered:
                    selected = all_models_ordered[0]
                    console.print(f"[dim]ä½¿ç”¨é»˜è®¤æ¨¡å‹: {selected}[/dim]")
                    return selected
                return None
            
            # å°è¯•æŒ‰åºå·é€‰æ‹©
            try:
                idx = int(choice)
                # æ£€æŸ¥æ˜¯å¦è¾“å…¥ 0 é€€å‡º
                if show_exit_option and idx == 0:
                    return "__EXIT__"
                
                idx = idx - 1  # è½¬æ¢ä¸ºæ•°ç»„ç´¢å¼•
                if 0 <= idx < len(all_models_ordered):
                    selected = all_models_ordered[idx]
                    console.print(f"[green]âœ“ å·²é€‰æ‹©æ¨¡å‹: {selected}[/green]")
                    return selected
                else:
                    console.print("[red]åºå·è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°è¾“å…¥[/red]")
            except ValueError:
                # æŒ‰åç§°é€‰æ‹©
                if choice in models:
                    console.print(f"[green]âœ“ å·²é€‰æ‹©æ¨¡å‹: {choice}[/green]")
                    return choice
                else:
                    # æ¨¡ç³ŠåŒ¹é…
                    matches = [m for m in models if choice.lower() in m.lower()]
                    if len(matches) == 1:
                        console.print(f"[green]âœ“ å·²é€‰æ‹©æ¨¡å‹: {matches[0]}[/green]")
                        return matches[0]
                    elif len(matches) > 1:
                        console.print(f"[yellow]æ‰¾åˆ°å¤šä¸ªåŒ¹é…: {', '.join(matches[:5])}[/yellow]")
                        console.print("[yellow]è¯·è¾“å…¥æ›´ç²¾ç¡®çš„åç§°[/yellow]")
                    else:
                        console.print("[red]æœªæ‰¾åˆ°åŒ¹é…çš„æ¨¡å‹ï¼Œè¯·é‡æ–°è¾“å…¥[/red]")
    
    def select_embedding_model(self) -> Optional[str]:
        """é€‰æ‹©åµŒå…¥æ¨¡å‹"""
        models_result = self.results.get("models_list", {})
        models = models_result.get("models", [])
        
        # æŸ¥æ‰¾åµŒå…¥æ¨¡å‹
        embed_models = [m for m in models if "embed" in m.lower()]
        
        if embed_models:
            console.print(f"\n[bold]é€‰æ‹© Embeddings æµ‹è¯•æ¨¡å‹:[/bold]")
            for i, m in enumerate(embed_models, 1):
                console.print(f"  [green]{i}[/green]. {m}")
            
            choice = console.input("[bold]è¯·è¾“å…¥é€‰æ‹© (åºå·ï¼Œç›´æ¥å›è½¦ä½¿ç”¨ç¬¬ä¸€ä¸ªï¼Œè¾“å…¥ 'skip' è·³è¿‡): [/bold]").strip()
            
            if choice.lower() == 'skip':
                return None
            
            if not choice:
                return embed_models[0]
            
            try:
                idx = int(choice) - 1
                if 0 <= idx < len(embed_models):
                    return embed_models[idx]
            except ValueError:
                pass
            
            return embed_models[0]
        else:
            # æ²¡æœ‰æ‰¾åˆ°åµŒå…¥æ¨¡å‹
            console.print(f"\n[yellow]âš ï¸ æœªåœ¨æ¨¡å‹åˆ—è¡¨ä¸­æ‰¾åˆ°åµŒå…¥æ¨¡å‹ (embedding)[/yellow]")
            choice = console.input("[bold]æ˜¯å¦ä»è¦æµ‹è¯• Embeddings? (è¾“å…¥æ¨¡å‹åæˆ–ç›´æ¥å›è½¦è·³è¿‡): [/bold]").strip()
            
            if not choice:
                return None  # è·³è¿‡æµ‹è¯•
            
            return choice  # ä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„æ¨¡å‹å
    
    def test_single_model(self, model: str) -> Dict[str, Any]:
        """æµ‹è¯•å•ä¸ªæ¨¡å‹çš„æ‰€æœ‰åŠŸèƒ½"""
        console.print(f"\n[bold blue]ğŸš€ å¼€å§‹ä½¿ç”¨æ¨¡å‹ [{model}] è¿›è¡ŒåŠŸèƒ½æµ‹è¯•...[/bold blue]")
        console.print("=" * 50)
        
        # æ¸…ç©ºä¹‹å‰çš„æµ‹è¯•ç»“æœï¼ˆä¿ç•™æ¨¡å‹åˆ—è¡¨ï¼‰
        models_list = self.results.get("models_list", {})
        self.results = {"models_list": models_list, "tested_model": model}
        
        # ä½¿ç”¨é€‰å®šçš„æ¨¡å‹è¿›è¡Œå„é¡¹æµ‹è¯•
        self.test_chat_completion(model=model)
        self.test_stream_mode(model=model)
        self.test_function_calling(model=model)
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self._print_summary()
        
        # ä¿å­˜åˆ°æµ‹è¯•å†å²
        self.all_test_history.append({
            "model": model,
            "chat": self.results.get("chat_completion", {}),
            "stream": self.results.get("stream_mode", {}),
            "tools": self.results.get("function_calling", {}),
            "embeddings": self.results.get("embeddings", {})
        })
        
        return self.results
    
    def _print_final_report(self):
        """æ‰“å°æœ€ç»ˆå¯¹æ¯”æŠ¥å‘Š"""
        if not self.all_test_history:
            return
        
        console.print("\n")
        console.print(Panel.fit(
            f"[bold]ğŸ“Š æµ‹è¯•æ€»ç»“æŠ¥å‘Š[/bold]\n[dim]å…±æµ‹è¯• {len(self.all_test_history)} ä¸ªæ¨¡å‹[/dim]",
            border_style="blue"
        ))
        
        # æµå¼è´¨é‡æè¿°æ˜ å°„
        stream_quality_desc = {
            "excellent": "çœŸæ­£æµå¼",
            "good": "æµå¼æ”¯æŒ",
            "poor": "ä¼ªæµå¼",
            "non-standard": "éæ ‡å‡†",
            "not_supported": "ä¸æ”¯æŒ",
            "unknown": "æœªçŸ¥"
        }
        
        # åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
        table = Table(show_header=True, header_style="bold magenta", title="æ¨¡å‹åŠŸèƒ½å¯¹æ¯”")
        table.add_column("æ¨¡å‹", style="cyan", max_width=30)
        table.add_column("å¯¹è¯", justify="center")
        table.add_column("Stream", justify="center")
        table.add_column("å·¥å…·è°ƒç”¨", justify="center")
        
        for record in self.all_test_history:
            model_name = record["model"]
            # æˆªæ–­è¿‡é•¿çš„æ¨¡å‹å
            if len(model_name) > 28:
                model_name = model_name[:25] + "..."
            
            # å¯¹è¯çŠ¶æ€
            chat = record.get("chat", {})
            chat_status = "[green]âœ…[/green]" if chat.get("success") else "[red]âŒ[/red]"
            
            # Stream çŠ¶æ€
            stream = record.get("stream", {})
            if stream.get("success"):
                quality = stream.get("stream_quality", "unknown")
                quality_text = stream_quality_desc.get(quality, quality)
                stream_status = f"[green]âœ…[/green] {quality_text}"
            else:
                stream_status = "[red]âŒ[/red]"
            
            # å·¥å…·è°ƒç”¨çŠ¶æ€
            tools = record.get("tools", {})
            if tools.get("success"):
                if tools.get("tool_called"):
                    tools_status = "[green]âœ… æ”¯æŒ[/green]"
                else:
                    tools_status = "[yellow]âš ï¸ æœªè°ƒç”¨[/yellow]"
            else:
                tools_status = "[red]âŒ[/red]"
            
            table.add_row(model_name, chat_status, stream_status, tools_status)
        
        console.print(table)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total = len(self.all_test_history)
        chat_pass = sum(1 for r in self.all_test_history if r.get("chat", {}).get("success"))
        stream_pass = sum(1 for r in self.all_test_history if r.get("stream", {}).get("success"))
        tools_pass = sum(1 for r in self.all_test_history if r.get("tools", {}).get("tool_called"))
        
        console.print(f"\n[bold]ç»Ÿè®¡:[/bold]")
        console.print(f"  å¯¹è¯æˆåŠŸ: {chat_pass}/{total}")
        console.print(f"  Stream æ”¯æŒ: {stream_pass}/{total}")
        console.print(f"  å·¥å…·è°ƒç”¨æ”¯æŒ: {tools_pass}/{total}")
    
    def run_loop_mode(self) -> None:
        """å¾ªç¯æµ‹è¯•æ¨¡å¼ - æµ‹è¯•å®Œæˆåè¿”å›æ¨¡å‹åˆ—è¡¨ï¼Œè¾“å…¥ 0 é€€å‡º"""
        console.print(Panel.fit(
            "[bold]OpenAI å…¬ç›Šç«™æ£€æµ‹å·¥å…·[/bold]\n"
            f"[dim]API åœ°å€: {self.base_url}[/dim]",
            border_style="blue"
        ))
        
        # 1. é¦–å…ˆè·å–æ¨¡å‹åˆ—è¡¨
        self.test_models_list()
        
        if not self.results.get("models_list", {}).get("success"):
            console.print("[red]æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ï¼Œè¯·æ£€æŸ¥ API åœ°å€å’Œ Key[/red]")
            return
        
        # 2. å¾ªç¯æµ‹è¯•
        test_count = 0
        while True:
            test_count += 1
            
            if test_count > 1:
                console.print("\n" + "=" * 50)
                console.print("[bold cyan]ğŸ“‹ è¿”å›æ¨¡å‹åˆ—è¡¨[/bold cyan]")
            
            # è®©ç”¨æˆ·é€‰æ‹©æ¨¡å‹ï¼ˆæ˜¾ç¤ºé€€å‡ºé€‰é¡¹ï¼‰
            selected_model = self.select_model(show_exit_option=True)
            
            # æ£€æŸ¥æ˜¯å¦é€€å‡º
            if selected_model == "__EXIT__":
                # æ‰“å°æœ€ç»ˆå¯¹æ¯”æŠ¥å‘Š
                if self.all_test_history:
                    self._print_final_report()
                console.print("\n[bold green]ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼[/bold green]")
                break
            
            if not selected_model:
                console.print("[yellow]âš ï¸ æœªé€‰æ‹©æ¨¡å‹ï¼Œå°†ä½¿ç”¨é»˜è®¤æ¨¡å‹ gpt-3.5-turbo[/yellow]")
                selected_model = "gpt-3.5-turbo"
            
            # æµ‹è¯•é€‰å®šçš„æ¨¡å‹
            self.test_single_model(selected_model)
            
            console.print("\n[bold green]âœ… æœ¬è½®æµ‹è¯•å®Œæˆ![/bold green]")
    
    def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼ˆå•æ¬¡æ¨¡å¼ï¼Œå…¼å®¹æ—§æ¥å£ï¼‰"""
        console.print(Panel.fit(
            "[bold]OpenAI å…¬ç›Šç«™æ£€æµ‹å·¥å…·[/bold]\n"
            f"[dim]API åœ°å€: {self.base_url}[/dim]",
            border_style="blue"
        ))
        
        # 1. é¦–å…ˆè·å–æ¨¡å‹åˆ—è¡¨
        self.test_models_list()
        
        # 2. è®©ç”¨æˆ·é€‰æ‹©æ¨¡å‹
        selected_model = self.select_model()
        
        if not selected_model:
            console.print("[yellow]âš ï¸ æœªé€‰æ‹©æ¨¡å‹ï¼Œå°†ä½¿ç”¨é»˜è®¤æ¨¡å‹ gpt-3.5-turbo[/yellow]")
            selected_model = "gpt-3.5-turbo"
        
        # 3. æµ‹è¯•é€‰å®šçš„æ¨¡å‹
        self.test_single_model(selected_model)
        
        return self.results
    
    def _print_summary(self):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        tested_model = self.results.get("tested_model", "æœªçŸ¥")
        
        console.print("\n")
        console.print(Panel.fit(f"[bold]ğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦[/bold]\n[dim]æµ‹è¯•æ¨¡å‹: {tested_model}[/dim]", border_style="blue"))
        
        table = Table(show_header=True, header_style="bold magenta")
        table.add_column("æµ‹è¯•é¡¹ç›®", style="cyan")
        table.add_column("çŠ¶æ€", justify="center")
        table.add_column("å“åº”æ—¶é—´", justify="right")
        table.add_column("å¤‡æ³¨")
        
        # æµå¼è´¨é‡æè¿°æ˜ å°„
        stream_quality_desc = {
            "excellent": "çœŸæ­£æµå¼",
            "good": "æµå¼æ”¯æŒ",
            "poor": "ä¼ªæµå¼",
            "non-standard": "éæ ‡å‡†æ ¼å¼",
            "not_supported": "ä¸æ”¯æŒ",
            "unknown": "æœªçŸ¥"
        }
        
        def get_stream_note(r):
            chunks = r.get('chunks_received', 0)
            quality = r.get('stream_quality', 'unknown')
            quality_text = stream_quality_desc.get(quality, quality)
            if chunks > 0:
                return f"{chunks} å— ({quality_text})"
            return quality_text
        
        test_items = [
            ("æ¨¡å‹åˆ—è¡¨", "models_list", lambda r: f"{len(r.get('models', []))} ä¸ªæ¨¡å‹"),
            ("åŸºç¡€å¯¹è¯", "chat_completion", lambda r: r.get("model_used", "")),
            ("Stream æ¨¡å¼", "stream_mode", get_stream_note),
            ("å·¥å…·è°ƒç”¨", "function_calling", lambda r: "å·²è°ƒç”¨" if r.get("tool_called") else "æœªè°ƒç”¨"),
        ]
        
        for name, key, note_func in test_items:
            result = self.results.get(key, {})
            # å¤„ç†è·³è¿‡çš„æµ‹è¯•
            if result.get("skipped"):
                status = "[yellow]â­ï¸ è·³è¿‡[/yellow]"
                note = "ç”¨æˆ·è·³è¿‡"
            elif result.get("success"):
                status = "[green]âœ… é€šè¿‡[/green]"
                note = note_func(result)
            else:
                status = "[red]âŒ å¤±è´¥[/red]"
                error = result.get("error", "")
                note = (error[:30] + "...") if error and len(error) > 30 else error
            response_time = f"{result.get('response_time', 0)}s"
            table.add_row(name, status, response_time, note or "-")
        
        console.print(table)
        
        # ç»Ÿè®¡ï¼ˆè¿‡æ»¤æ‰éå­—å…¸ç±»å‹çš„å€¼ï¼Œå¦‚ tested_modelï¼‰
        test_results = [r for r in self.results.values() if isinstance(r, dict)]
        passed = sum(1 for r in test_results if r.get("success"))
        total = len(test_results)
        console.print(f"\n[bold]æ€»è®¡: {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡[/bold]")


def main():
    """ä¸»å‡½æ•°"""
    console.print(Panel.fit(
        "[bold blue]ğŸ” OpenAI å…¬ç›Šç«™æ£€æµ‹å·¥å…·[/bold blue]\n"
        "[dim]æµ‹è¯• OpenAI å…¼å®¹æ¥å£çš„å„ç§åŠŸèƒ½[/dim]",
        border_style="blue"
    ))
    
    # è·å–ç”¨æˆ·è¾“å…¥
    console.print("\n[bold]è¯·è¾“å…¥ API ä¿¡æ¯:[/bold]")
    
    base_url = console.input("[cyan]API Base URL[/cyan] (å¦‚ https://api.openai.com/v1): ").strip()
    if not base_url:
        console.print("[red]é”™è¯¯: API Base URL ä¸èƒ½ä¸ºç©º[/red]")
        return
    
    api_key = console.input("[cyan]API Key[/cyan]: ").strip()
    if not api_key:
        console.print("[red]é”™è¯¯: API Key ä¸èƒ½ä¸ºç©º[/red]")
        return
    
    # åˆ›å»ºæµ‹è¯•å™¨å¹¶è¿è¡Œå¾ªç¯æµ‹è¯•æ¨¡å¼
    tester = OpenAITester(base_url, api_key)
    
    console.print("\n[bold yellow]å¼€å§‹æµ‹è¯•...[/bold yellow]")
    console.print("=" * 50)
    
    # ä½¿ç”¨å¾ªç¯æµ‹è¯•æ¨¡å¼
    tester.run_loop_mode()


if __name__ == "__main__":
    main()
